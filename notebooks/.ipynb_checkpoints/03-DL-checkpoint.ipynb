{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98408a22-7ae9-4a81-886d-4bcf48cfcb63",
   "metadata": {},
   "source": [
    "# Intro neurale netwerken\n",
    "\n",
    "Leerdoelen\n",
    "\n",
    "Na deze notebook kan je:\n",
    "\n",
    "- het verschil uitleggen tussen machine learning en deep learning;\n",
    "- beschrijven wat een neuron, laag en activatiefunctie is;\n",
    "- een eenvoudig neuraal netwerk bouwen met Keras;\n",
    "- een model trainen, evalueren en interpreteren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ab6ee-1262-4d25-95f4-4a6eefe5c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53819b96-c7ca-44e2-a12d-64b08d9ee422",
   "metadata": {},
   "source": [
    "## Natuurlijke neuronen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac6c85-120a-4faf-b8c7-c7f555d3314f",
   "metadata": {},
   "source": [
    "![](figures/LabeledNeuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e4400-7ea6-490b-b059-879d361ce729",
   "metadata": {},
   "source": [
    "![](figures/neural_connection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247de421-d479-48a1-8e10-ccd805b1babe",
   "metadata": {},
   "source": [
    "## Kunstmatige neuronen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c8f29-6354-408b-96c9-c0f258f47506",
   "metadata": {},
   "source": [
    "![](figures/perceptron-with-neuron_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fac5571-ec72-4b6d-9b67-6c067c9b4312",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "![](figures/ann_left.png)\n",
    "\n",
    "$ s = x_1 w_1 + x_2 w_2 + \\dots + b $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8636c7-f537-4c75-b3aa-b832abdc4c59",
   "metadata": {},
   "source": [
    "#### Vraagje\n",
    "\n",
    "Hoe schrijven we dit compacter? Tip: gebruik lineaire algebra?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047ad62-2cd1-40da-b815-d8c8cef61e9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Oplossing\n",
    "\n",
    "$ s = \\vec{x} \\cdot \\vec{w} + b $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62f4d7-1711-4a37-a180-32000173778d",
   "metadata": {},
   "source": [
    "![](figures/ann.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e0049-6ee4-4135-9bc6-8d192d1f1a42",
   "metadata": {},
   "source": [
    "$ O = f (\\vec{x} \\cdot \\vec{w} + B) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7b024-eede-40de-9e91-028d59c32e2e",
   "metadata": {},
   "source": [
    "### De ReLU-functie\n",
    "\n",
    "Nadat een neuron zijn inputs lineair combineert en sommeert met een *bias*, wordt er meestal nog een niet-lineaire functie toegepast.  Dit maakt de neuron \"expressiever\".  Deze functie heet de activatiefunctie van het neuron.  Er bestaan vele varianten van, maar wij zien enkel de belangrijkste.\n",
    "\n",
    "De output van de ReLU-functie (*Rectified Linear Unit*) is 0 als $s_i$ negatief is, en $s_i$ als $s_i$ positief is.  Het is dus een stuksgewijs gedefinieerde functie:\n",
    "\n",
    "$$\n",
    "ReLU(s_i)\n",
    "\\begin{cases} \n",
    "      0,   \\,\\text{als}\\, s_i \\leq 0 \\\\\n",
    "      s_i, \\,\\text{als}\\, s_i > 0\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Opdracht\n",
    "\n",
    "- Maak een 1D array `x` aan met waarden tussen -10 en 10.  Tip: gebruik `np.linspace(<min>, <max>, <aantal)`.\n",
    "- Bereken de array `y` die de softmax-functie van alle elementen van `x` bevat.  Tip: gebruik een `for` en `if`.\n",
    "- Plot `y` in functie van `x`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18402c2-2e00-448a-a5c5-94adfeecc88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18bc5720-a408-468c-851e-7c3e27c049ef",
   "metadata": {},
   "source": [
    "## Neurale netwerken\n",
    "\n",
    "*Dense net*: alle neuronen van alle lagen verbonden met alle neuronen van vorige en volgende laag\n",
    "\n",
    "![](figures/mnist_net.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4471f-a134-4160-9991-cfb4db276ded",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24fc0b2b-753d-4e39-91b7-9cd46ce8ddce",
   "metadata": {},
   "source": [
    "n## Nog een (klein) beetje wiskunde.\n",
    "\n",
    "### Output van het j-de neuron in de i-de laag\n",
    "\n",
    "$x_{j} = x_{0} w_{j,0} + x_{1} w_{j,1} + \\dots + b_{j} = \\vec{x} \\cdot \\vec{w}_j + b_{j} $\n",
    "\n",
    "met \n",
    "\n",
    "$\\vec{x} = \\begin{bmatrix}\n",
    "x_0\\\\\n",
    "x_1\\\\\n",
    "\\dots\n",
    "\\end{bmatrix}$ de inputvector naar laag $i$,\n",
    "\n",
    "$\\vec{w}_j = \\begin{bmatrix}\n",
    "w_{j,0}\\\\\n",
    "w_{j,1}\\\\\n",
    "\\dots\n",
    "\\end{bmatrix}$ de vector met de gewichten van het $j$-de neuron van laag $i$ en \n",
    "\n",
    "$b_j$ de bias van van dat neuron. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81151c-c274-4176-b2ac-0a142fdafe8d",
   "metadata": {},
   "source": [
    "### Matrix-vector product\n",
    "\n",
    "![](figures/MatrixDefFigure7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a216c-afda-4ef6-8708-06aa195cdb80",
   "metadata": {},
   "source": [
    "### Opdracht\n",
    "\n",
    "Wat is de output van alle neuronen in de $i$-de laag?  \n",
    "\n",
    "Tip: Zet de gewichten van de neuronen samen in een matrix:\n",
    "\n",
    "$ W_i = \\begin{bmatrix}\n",
    "w_{0,0} & w_{0,1} & w_{0,2} & \\dots\\\\\n",
    "w_{1,0} & w_{1,1} & w_{1,2} & \\dots\\\\\n",
    "\\dots   & \\dots   & \\dots   & \\dots\n",
    "\\end{bmatrix}$\n",
    "\n",
    "en de biases in een vector\n",
    "\n",
    "$\\vec{b_i} = \\begin{bmatrix}\n",
    "b_0\\\\\n",
    "b_1\\\\\n",
    "b_2\\\\\n",
    "\\dots\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d90e78c-35cf-4a08-8c41-b43a4e9ff23d",
   "metadata": {},
   "source": [
    "### Laag na laag\n",
    "\n",
    "<u>Start \n",
    "\n",
    "$\\vec{x}_0$\n",
    "\n",
    "(wat is dit?)\n",
    "\n",
    "\n",
    "<u>Laag 0:\n",
    "\n",
    "$\\vec{x}_1 = f_0(W_0 \\vec{x}_0 + \\vec{b}_0)$\n",
    "\n",
    "<u>Laag 1:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\vec{x}_2 &= f_1(W_1 \\vec{x}_1 + \\vec{b}_1) \\\\\n",
    "          &= f_1\\left(W_1 (f_0(W_0 \\vec{x}_0 + \\vec{b}_0)\\right) + \\vec{b}_2)\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "\n",
    "<u>Laag 2:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\vec{x}_3 &= f_2(W_2 \\vec{x}_2 + \\vec{b}_2) \\\\\n",
    "          &= f_2 \\left(W_2 \\left(f_1 \\left(W_1 \\vec{x}_1 + \\vec{b}_1 \\right) \\right) + \\vec{b}_2\\right) \\\\\n",
    "          &= f_2\\left(W_2 \\left(f_1 \\left(W_1 \\left(f_0 \\left(W_0 \\vec{x}_0 + \\vec{b}_0 \\right) \\right) + \\vec{b}_1 \\right) \\right) + \\vec{b}_2 \\right)          \n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d275a-87b0-4f99-b07b-da0b3e0495fb",
   "metadata": {},
   "source": [
    "Oplossing\n",
    "\n",
    "$\\vec{x}_{i+1} = f(W_i \\vec{x}_i + \\vec{b}_i)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af58703f-44e5-42bf-a0a2-7b428a163932",
   "metadata": {},
   "source": [
    "#### Vraagjes\n",
    "\n",
    "- Hebben de vectoren $\\vec{x_0}$, $\\vec{x_1}$, enz. dezelfde grootte?  Waarom (niet)?\n",
    "\n",
    "- Hoe groot zou je de outputvector maken als je cijfers wilt classificeren?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a14503-454b-41d6-abaf-fa89d216d19f",
   "metadata": {},
   "source": [
    "### De softmax-functie \n",
    "\n",
    "Stel dat we een laag van tien neuronen hebben, en dat we voor een iris de $s$-waarden van alle neuronen hebben berekend.  Dit kunnen we schrijven als een vector $\\vec{s} = \\begin{bmatrix}s_0\\\\s_1\\\\\\dots\\\\s_{9}\\end{bmatrix}$.  \n",
    "Deze waarden kunnen in principe overal tussen $-\\infty$0 en $+\\infty$ zitten.  De softmax-functie brengt alle outputs van de neuronen van deze laag tussen de waarden 0 en 1.\n",
    "\n",
    "Eerst berekenen we de exponentiele functie van alle gewogen sommen: $e^{s_i}$.  Deze sommeren we: $\\sum_{i} e^{s_i}$.  Tenslotte delen we elke $e^{s_i}$ door die som: \n",
    "\n",
    "$$\\sigma(s_i) = \\frac{e_{s_i}}{\\sum_{i} e^{s_i}}$$\n",
    "\n",
    "Aangezien de outputs van de softmax-functie tussen 0 en 1 liggen, en sommeren tot 1, kunnen ze geinterpreteerd worden als waarschijnlijkheden van klassen.  Dit zal van pas komen bij de klassificatietaak (zie verder)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c2985-a7fd-49bd-b33a-33f16d63013a",
   "metadata": {},
   "source": [
    "#### Opdracht\n",
    "\n",
    "Stel dat we een laag met vier neuronen hebben, en dat die als lineaire outputs -5, 10, 8 en 3 hebben. \n",
    "\n",
    "- Bereken de output van de softmax-functie voor elke van deze neuronen.\n",
    "- Plot dit in een staafdiagram.  Tip: gebruik `plt.bar(x = ..., height = ...)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07943a-6574-4da9-822a-c86c4827d5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48a2c2be-dd6b-4cda-9f34-96e3e271b4b7",
   "metadata": {},
   "source": [
    "#### Opdracht\n",
    "\n",
    "Waarom kunnen we niet gewoon de softmax-functie plotten voor een array met waarden van -10 tot 10, zoals we deden bij de ReLU-functie?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7518672-c6f6-4bd8-9a71-9f2592489591",
   "metadata": {},
   "source": [
    "## Toepassen op de iris dataset\n",
    "\n",
    "#### Opdracht\n",
    "\n",
    "- Laad de iris dataset opnieuw\n",
    "- Split in train en test set.\n",
    "- Split de train en test set elk in een feature matrix en een target vector: `X_train`, `X_test`, `y_train`, `y_test`.  Al deze objecten moeten numpy arrays zijn.  \n",
    "- Zet de strings  (`Iris-versicolor`, `Iris-virginica`, `Iris-setosa`) in de targets om naar respectievelijk de getallen 0, 1 en 2.  Zorg dat elke array een numerieke elementen heeft, geen strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e0bb5-a474-4fbe-a150-1f6faa233b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2f614-da40-4cfc-8a12-e3a4e64d7e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9af19-5546-43e2-9556-dbed7432159b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1bd34-18c7-4aac-bc36-6f9fa27813f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebe21b-8cbc-43d7-a2e2-0160bee92362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31a42724-a062-4067-88d5-bdb9ee351959",
   "metadata": {},
   "source": [
    "### Neuraal netwerk\n",
    "\n",
    "De package `torch` laat ons toe om heel eenvoudig met neurale netwerken te werken.  In onderstaande code maken we eerst een netwerk met drie lagen aan.  Daarna trainen we het netwerk op de train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9b725-180f-46a3-8919-3759941a81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 50)\n",
    "        self.layer2 = nn.Linear(50, 50)\n",
    "        self.layer3 = nn.Linear(50, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model     = Model(X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn   = nn.CrossEntropyLoss()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0254e5-420b-4da0-9b8c-1ced551ca30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "EPOCHS  = 100\n",
    "X_train = Variable(torch.from_numpy(X_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()\n",
    "X_test  = Variable(torch.from_numpy(X_test)).float()\n",
    "y_test  = Variable(torch.from_numpy(y_test)).long()\n",
    "\n",
    "loss_list     = np.zeros((EPOCHS,))\n",
    "accuracy_list = np.zeros((EPOCHS,))\n",
    "\n",
    "for epoch in tqdm.trange(EPOCHS):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss_list[epoch] = loss.item()\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
    "        accuracy_list[epoch] = correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd4380-06cd-4ea8-a2b3-5750d49ba2a9",
   "metadata": {},
   "source": [
    "Het model is nu klaar om voorspellingen te maken.  Voor elke input geeft het als output drie waarschijnlijkheden (een voor elke klasse).\n",
    "\n",
    "#### Opdracht\n",
    "\n",
    "- Voorspel de test set met het getrained model.  Tip: gebruik `model(X_test)`.\n",
    "- Evalueer het model\n",
    "    - Maak een lijst met voor elke voorspelling de index (0, 1 of 2) van de klasse met de hoogste waarschijnlijkheid.\n",
    "    - Tel het aantal keren dat de voorspelde index gelijk is aan de ware index (in `y_test`).\n",
    "    - Bereken de accuraatheid van het model voor de test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c411a7-de1a-4676-95fc-9e602edaa7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "503430b5-3e88-486d-9ead-e74db4c4c7b2",
   "metadata": {},
   "source": [
    "#### Bronnen\n",
    "\n",
    "https://janakiev.com/blog/pytorch-iris/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
